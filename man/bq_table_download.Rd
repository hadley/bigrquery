% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/bq-download.R
\name{bq_table_download}
\alias{bq_table_download}
\title{Download table data}
\usage{
bq_table_download(x, max_results = Inf, page_size = 10000,
  start_index = 0L)
}
\arguments{
\item{x}{A \link{bq_table}}

\item{max_results}{Maximum number of results to retrieve. Use \code{Inf}
retrieve all rows.}

\item{page_size}{The number of rows returned per page. Make this smaller
if you have many fields or large records and you are seeing a
"responseTooLarge" error.}

\item{start_index}{Starting row index (zero-based).}
}
\description{
This retrieves rows in chunks of \code{page_size}. It is most suitable for results
of smaller queries (<100 meg, say). For larger queries, it is better to
export the results to a CSV file stored on google cloud and use the
bq command line tool to download locally.
}
\section{API documentation}{

\itemize{
\item \href{https://developers.google.com/bigquery/docs/reference/v2/tabledata/list}{list}
}
}

\examples{
if (bq_testable()) {
df <- bq_table_download("publicdata.samples.natality", max_results = 35000)
}
}
